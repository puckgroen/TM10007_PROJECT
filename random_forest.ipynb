{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37464bitbaseconda3e433ad4382c432eac770014b82f80bd",
   "display_name": "Python 3.7.4 64-bit ('base': conda)"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Import packages\n",
    "\n",
    "# General packages\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn import datasets as ds\n",
    "import seaborn\n",
    "\n",
    "# Classifiers\n",
    "from sklearn import model_selection\n",
    "from sklearn import metrics\n",
    "from sklearn import feature_selection \n",
    "from sklearn import preprocessing\n",
    "from sklearn import neighbors\n",
    "from sklearn import svm\n",
    "from sklearn import decomposition\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import PCA, KernelPCA\n",
    "from sklearn.kernel_approximation import RBFSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_curve(estimator, title, X, y, axes, ylim=None, cv=None,\n",
    "                        n_jobs=None, train_sizes=np.linspace(.1, 1.0, 5)):\n",
    "    axes.set_title(title)\n",
    "    if ylim is not None:\n",
    "        axes.set_ylim(*ylim)\n",
    "    axes.set_xlabel(\"Training examples\")\n",
    "    axes.set_ylabel(\"Score\")\n",
    "\n",
    "    train_sizes, train_scores, test_scores  = \\\n",
    "        learning_curve(estimator, X, y, cv=cv, n_jobs=n_jobs,\n",
    "                       train_sizes=train_sizes)\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "\n",
    "    # Plot learning curve\n",
    "    axes.grid()\n",
    "    axes.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                         train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                         color=\"r\")\n",
    "    axes.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                         test_scores_mean + test_scores_std, alpha=0.1,\n",
    "                         color=\"g\")\n",
    "    axes.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "                 label=\"Training score\")\n",
    "    axes.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "                 label=\"Cross-validation score\")\n",
    "    axes.legend(loc=\"best\")\n",
    "\n",
    "    return plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "The number of samples: 113\nThe number of features: 159\n"
    }
   ],
   "source": [
    "# Data\n",
    "from hn.load_data import load_data\n",
    "data = load_data()\n",
    "print(f'The number of samples: {len(data.index)}')\n",
    "print(f'The number of features: {len(data.columns)-1}')\n",
    "y_labels = data['label']\n",
    "del data['label']\n",
    "\n",
    "y = sklearn.preprocessing.label_binarize(y_labels, ['T12', 'T34']) # 0 now stands for T12 and 1 for T34\n",
    "y = [i[0] for i in y]\n",
    "y = np.array(y)\n",
    "\n",
    "cv_4fold = model_selection.StratifiedKFold(n_splits=4, shuffle=True)\n",
    "split_X_train, split_X_test, split_y_train, split_y_test = train_test_split(data, y,\n",
    "                                                    stratify=y, \n",
    "                                                    test_size=0.2)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Loop over the folds\n",
    "for training_index, validation_index in cv_4fold.split(split_X_train, split_y_train):\n",
    "    X_validation = split_X_train.iloc[validation_index]\n",
    "    y_validation = split_y_train[validation_index]\n",
    "    X_train = split_X_train.iloc[training_index]\n",
    "    y_train = split_y_train[training_index]\n",
    "    #print(f'Validation size in current fold = {len(X_validation)}')\n",
    "\n",
    "    scaler = preprocessing.StandardScaler()\n",
    "    # scaler = preprocessing.MinMaxScaler()\n",
    "    # scaler = preprocessing.RobustScaler()\n",
    "    scaler.fit(X_train)\n",
    "    X_test_scaled = scaler.transform(X_validation)\n",
    "    X_train_scaled = scaler.transform(X_train)\n",
    "    #apply preprocessing\n",
    "\n",
    "    n_selected_features = 10\n",
    "    n_samples = len(X_train.index)\n",
    "    n_components = min(n_samples, n_selected_features)\n",
    "    pca = decomposition.PCA(n_components)\n",
    "    pca.fit(X_train_scaled)\n",
    "    X_train_pca = pca.transform(X_train_scaled)\n",
    "    X_validation_pca = pca.transform(X_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the lecture, we have seen that a random forest has a natural form of feature selection and feature importance. Hence, you may use this feature to find out which features have the most predictive value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Opties --> (n_estimators=100, criterion='gini', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features='auto', max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, bootstrap=True, oob_score=False, n_jobs=None, random_state=None, verbose=0, warm_start=False, class_weight=None, ccp_alpha=0.0, max_samples=None)\n",
    "\n",
    "In opdracht 2.1\n",
    "n_estimators = kan alles zijn\n",
    "bootstrap = True False allebei gebruikt\n",
    "class_weight gevarieerd\n",
    "\n",
    "Lastly, if you have an imbalance in your dataset, or one class is more important than the other, you may want\n",
    "to alter the class weigh in the random forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stratified K-fold Cross validation\n",
    "k=4 # K-fold\n",
    "skf = StratifiedKFold(k, random_state=0) \n",
    "# cv kan ook op None --> geeft default --> 5-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Fitting 4 folds for each of 20 candidates, totalling 80 fits\n[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n[Parallel(n_jobs=-1)]: Done  47 tasks      | elapsed:    6.8s\n[Parallel(n_jobs=-1)]: Done  80 out of  80 | elapsed:   12.3s finished\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n0        0.045576      0.003659         0.003035        0.000581   \n1        0.364433      0.019454         0.033037        0.011247   \n2        0.409993      0.042606         0.073391        0.032532   \n3        1.066013      0.164501         0.063850        0.017354   \n4        1.788096      0.103407         0.092067        0.003814   \n5        0.036658      0.006549         0.002496        0.000074   \n6        0.183432      0.007199         0.011111        0.002742   \n7        0.477816      0.082104         0.043994        0.020770   \n8        0.722489      0.013397         0.042944        0.001808   \n9        1.649211      0.153111         0.114786        0.048117   \n10       0.026604      0.006087         0.003323        0.001207   \n11       0.141045      0.015115         0.011570        0.002370   \n12       0.290257      0.029817         0.024603        0.005101   \n13       0.636113      0.073775         0.051512        0.013829   \n14       1.439686      0.068289         0.105004        0.020416   \n15       0.030668      0.004044         0.003361        0.001148   \n16       0.143039      0.005080         0.014706        0.002452   \n17       0.276965      0.006296         0.025691        0.004179   \n18       0.537278      0.005300         0.043568        0.003237   \n19       1.074315      0.017568         0.081711        0.016315   \n\n   param_bootstrap param_criterion param_n_estimators  \\\n0             True            gini                 10   \n1             True            gini                 50   \n2             True            gini                100   \n3             True            gini                200   \n4             True            gini                400   \n5             True         entropy                 10   \n6             True         entropy                 50   \n7             True         entropy                100   \n8             True         entropy                200   \n9             True         entropy                400   \n10           False            gini                 10   \n11           False            gini                 50   \n12           False            gini                100   \n13           False            gini                200   \n14           False            gini                400   \n15           False         entropy                 10   \n16           False         entropy                 50   \n17           False         entropy                100   \n18           False         entropy                200   \n19           False         entropy                400   \n\n                                               params  split0_test_score  \\\n0   {'bootstrap': True, 'criterion': 'gini', 'n_es...           0.470588   \n1   {'bootstrap': True, 'criterion': 'gini', 'n_es...           0.529412   \n2   {'bootstrap': True, 'criterion': 'gini', 'n_es...           0.529412   \n3   {'bootstrap': True, 'criterion': 'gini', 'n_es...           0.529412   \n4   {'bootstrap': True, 'criterion': 'gini', 'n_es...           0.529412   \n5   {'bootstrap': True, 'criterion': 'entropy', 'n...           0.647059   \n6   {'bootstrap': True, 'criterion': 'entropy', 'n...           0.588235   \n7   {'bootstrap': True, 'criterion': 'entropy', 'n...           0.529412   \n8   {'bootstrap': True, 'criterion': 'entropy', 'n...           0.529412   \n9   {'bootstrap': True, 'criterion': 'entropy', 'n...           0.529412   \n10  {'bootstrap': False, 'criterion': 'gini', 'n_e...           0.588235   \n11  {'bootstrap': False, 'criterion': 'gini', 'n_e...           0.529412   \n12  {'bootstrap': False, 'criterion': 'gini', 'n_e...           0.529412   \n13  {'bootstrap': False, 'criterion': 'gini', 'n_e...           0.529412   \n14  {'bootstrap': False, 'criterion': 'gini', 'n_e...           0.529412   \n15  {'bootstrap': False, 'criterion': 'entropy', '...           0.529412   \n16  {'bootstrap': False, 'criterion': 'entropy', '...           0.470588   \n17  {'bootstrap': False, 'criterion': 'entropy', '...           0.529412   \n18  {'bootstrap': False, 'criterion': 'entropy', '...           0.529412   \n19  {'bootstrap': False, 'criterion': 'entropy', '...           0.470588   \n\n    split1_test_score  split2_test_score  split3_test_score  mean_test_score  \\\n0            0.588235           0.529412           0.647059         0.558824   \n1            0.647059           0.588235           0.647059         0.602941   \n2            0.764706           0.529412           0.647059         0.617647   \n3            0.764706           0.529412           0.647059         0.617647   \n4            0.882353           0.470588           0.647059         0.632353   \n5            0.588235           0.529412           0.529412         0.573529   \n6            0.588235           0.529412           0.647059         0.588235   \n7            0.764706           0.470588           0.647059         0.602941   \n8            0.823529           0.529412           0.647059         0.632353   \n9            0.882353           0.529412           0.647059         0.647059   \n10           0.647059           0.470588           0.764706         0.617647   \n11           0.764706           0.588235           0.705882         0.647059   \n12           0.647059           0.588235           0.588235         0.588235   \n13           0.823529           0.529412           0.705882         0.647059   \n14           0.823529           0.529412           0.647059         0.632353   \n15           0.647059           0.588235           0.352941         0.529412   \n16           0.823529           0.529412           0.588235         0.602941   \n17           0.705882           0.647059           0.588235         0.617647   \n18           0.647059           0.588235           0.647059         0.602941   \n19           0.705882           0.647059           0.588235         0.602941   \n\n    std_test_score  rank_test_score  \n0         0.065767               19  \n1         0.048774               12  \n2         0.097548                9  \n3         0.097548                9  \n4         0.157703                4  \n5         0.048774               18  \n6         0.041595               16  \n7         0.112958               12  \n8         0.120373                4  \n9         0.144088                3  \n10        0.106046                7  \n11        0.093008                1  \n12        0.041595               16  \n13        0.124784                1  \n14        0.120373                4  \n15        0.110049               20  \n16        0.133977               12  \n17        0.065767                7  \n18        0.048774               12  \n19        0.087001               11  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mean_fit_time</th>\n      <th>std_fit_time</th>\n      <th>mean_score_time</th>\n      <th>std_score_time</th>\n      <th>param_bootstrap</th>\n      <th>param_criterion</th>\n      <th>param_n_estimators</th>\n      <th>params</th>\n      <th>split0_test_score</th>\n      <th>split1_test_score</th>\n      <th>split2_test_score</th>\n      <th>split3_test_score</th>\n      <th>mean_test_score</th>\n      <th>std_test_score</th>\n      <th>rank_test_score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.045576</td>\n      <td>0.003659</td>\n      <td>0.003035</td>\n      <td>0.000581</td>\n      <td>True</td>\n      <td>gini</td>\n      <td>10</td>\n      <td>{'bootstrap': True, 'criterion': 'gini', 'n_es...</td>\n      <td>0.470588</td>\n      <td>0.588235</td>\n      <td>0.529412</td>\n      <td>0.647059</td>\n      <td>0.558824</td>\n      <td>0.065767</td>\n      <td>19</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.364433</td>\n      <td>0.019454</td>\n      <td>0.033037</td>\n      <td>0.011247</td>\n      <td>True</td>\n      <td>gini</td>\n      <td>50</td>\n      <td>{'bootstrap': True, 'criterion': 'gini', 'n_es...</td>\n      <td>0.529412</td>\n      <td>0.647059</td>\n      <td>0.588235</td>\n      <td>0.647059</td>\n      <td>0.602941</td>\n      <td>0.048774</td>\n      <td>12</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.409993</td>\n      <td>0.042606</td>\n      <td>0.073391</td>\n      <td>0.032532</td>\n      <td>True</td>\n      <td>gini</td>\n      <td>100</td>\n      <td>{'bootstrap': True, 'criterion': 'gini', 'n_es...</td>\n      <td>0.529412</td>\n      <td>0.764706</td>\n      <td>0.529412</td>\n      <td>0.647059</td>\n      <td>0.617647</td>\n      <td>0.097548</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.066013</td>\n      <td>0.164501</td>\n      <td>0.063850</td>\n      <td>0.017354</td>\n      <td>True</td>\n      <td>gini</td>\n      <td>200</td>\n      <td>{'bootstrap': True, 'criterion': 'gini', 'n_es...</td>\n      <td>0.529412</td>\n      <td>0.764706</td>\n      <td>0.529412</td>\n      <td>0.647059</td>\n      <td>0.617647</td>\n      <td>0.097548</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1.788096</td>\n      <td>0.103407</td>\n      <td>0.092067</td>\n      <td>0.003814</td>\n      <td>True</td>\n      <td>gini</td>\n      <td>400</td>\n      <td>{'bootstrap': True, 'criterion': 'gini', 'n_es...</td>\n      <td>0.529412</td>\n      <td>0.882353</td>\n      <td>0.470588</td>\n      <td>0.647059</td>\n      <td>0.632353</td>\n      <td>0.157703</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.036658</td>\n      <td>0.006549</td>\n      <td>0.002496</td>\n      <td>0.000074</td>\n      <td>True</td>\n      <td>entropy</td>\n      <td>10</td>\n      <td>{'bootstrap': True, 'criterion': 'entropy', 'n...</td>\n      <td>0.647059</td>\n      <td>0.588235</td>\n      <td>0.529412</td>\n      <td>0.529412</td>\n      <td>0.573529</td>\n      <td>0.048774</td>\n      <td>18</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0.183432</td>\n      <td>0.007199</td>\n      <td>0.011111</td>\n      <td>0.002742</td>\n      <td>True</td>\n      <td>entropy</td>\n      <td>50</td>\n      <td>{'bootstrap': True, 'criterion': 'entropy', 'n...</td>\n      <td>0.588235</td>\n      <td>0.588235</td>\n      <td>0.529412</td>\n      <td>0.647059</td>\n      <td>0.588235</td>\n      <td>0.041595</td>\n      <td>16</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0.477816</td>\n      <td>0.082104</td>\n      <td>0.043994</td>\n      <td>0.020770</td>\n      <td>True</td>\n      <td>entropy</td>\n      <td>100</td>\n      <td>{'bootstrap': True, 'criterion': 'entropy', 'n...</td>\n      <td>0.529412</td>\n      <td>0.764706</td>\n      <td>0.470588</td>\n      <td>0.647059</td>\n      <td>0.602941</td>\n      <td>0.112958</td>\n      <td>12</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>0.722489</td>\n      <td>0.013397</td>\n      <td>0.042944</td>\n      <td>0.001808</td>\n      <td>True</td>\n      <td>entropy</td>\n      <td>200</td>\n      <td>{'bootstrap': True, 'criterion': 'entropy', 'n...</td>\n      <td>0.529412</td>\n      <td>0.823529</td>\n      <td>0.529412</td>\n      <td>0.647059</td>\n      <td>0.632353</td>\n      <td>0.120373</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>1.649211</td>\n      <td>0.153111</td>\n      <td>0.114786</td>\n      <td>0.048117</td>\n      <td>True</td>\n      <td>entropy</td>\n      <td>400</td>\n      <td>{'bootstrap': True, 'criterion': 'entropy', 'n...</td>\n      <td>0.529412</td>\n      <td>0.882353</td>\n      <td>0.529412</td>\n      <td>0.647059</td>\n      <td>0.647059</td>\n      <td>0.144088</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>0.026604</td>\n      <td>0.006087</td>\n      <td>0.003323</td>\n      <td>0.001207</td>\n      <td>False</td>\n      <td>gini</td>\n      <td>10</td>\n      <td>{'bootstrap': False, 'criterion': 'gini', 'n_e...</td>\n      <td>0.588235</td>\n      <td>0.647059</td>\n      <td>0.470588</td>\n      <td>0.764706</td>\n      <td>0.617647</td>\n      <td>0.106046</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>0.141045</td>\n      <td>0.015115</td>\n      <td>0.011570</td>\n      <td>0.002370</td>\n      <td>False</td>\n      <td>gini</td>\n      <td>50</td>\n      <td>{'bootstrap': False, 'criterion': 'gini', 'n_e...</td>\n      <td>0.529412</td>\n      <td>0.764706</td>\n      <td>0.588235</td>\n      <td>0.705882</td>\n      <td>0.647059</td>\n      <td>0.093008</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>0.290257</td>\n      <td>0.029817</td>\n      <td>0.024603</td>\n      <td>0.005101</td>\n      <td>False</td>\n      <td>gini</td>\n      <td>100</td>\n      <td>{'bootstrap': False, 'criterion': 'gini', 'n_e...</td>\n      <td>0.529412</td>\n      <td>0.647059</td>\n      <td>0.588235</td>\n      <td>0.588235</td>\n      <td>0.588235</td>\n      <td>0.041595</td>\n      <td>16</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>0.636113</td>\n      <td>0.073775</td>\n      <td>0.051512</td>\n      <td>0.013829</td>\n      <td>False</td>\n      <td>gini</td>\n      <td>200</td>\n      <td>{'bootstrap': False, 'criterion': 'gini', 'n_e...</td>\n      <td>0.529412</td>\n      <td>0.823529</td>\n      <td>0.529412</td>\n      <td>0.705882</td>\n      <td>0.647059</td>\n      <td>0.124784</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>1.439686</td>\n      <td>0.068289</td>\n      <td>0.105004</td>\n      <td>0.020416</td>\n      <td>False</td>\n      <td>gini</td>\n      <td>400</td>\n      <td>{'bootstrap': False, 'criterion': 'gini', 'n_e...</td>\n      <td>0.529412</td>\n      <td>0.823529</td>\n      <td>0.529412</td>\n      <td>0.647059</td>\n      <td>0.632353</td>\n      <td>0.120373</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>0.030668</td>\n      <td>0.004044</td>\n      <td>0.003361</td>\n      <td>0.001148</td>\n      <td>False</td>\n      <td>entropy</td>\n      <td>10</td>\n      <td>{'bootstrap': False, 'criterion': 'entropy', '...</td>\n      <td>0.529412</td>\n      <td>0.647059</td>\n      <td>0.588235</td>\n      <td>0.352941</td>\n      <td>0.529412</td>\n      <td>0.110049</td>\n      <td>20</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>0.143039</td>\n      <td>0.005080</td>\n      <td>0.014706</td>\n      <td>0.002452</td>\n      <td>False</td>\n      <td>entropy</td>\n      <td>50</td>\n      <td>{'bootstrap': False, 'criterion': 'entropy', '...</td>\n      <td>0.470588</td>\n      <td>0.823529</td>\n      <td>0.529412</td>\n      <td>0.588235</td>\n      <td>0.602941</td>\n      <td>0.133977</td>\n      <td>12</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>0.276965</td>\n      <td>0.006296</td>\n      <td>0.025691</td>\n      <td>0.004179</td>\n      <td>False</td>\n      <td>entropy</td>\n      <td>100</td>\n      <td>{'bootstrap': False, 'criterion': 'entropy', '...</td>\n      <td>0.529412</td>\n      <td>0.705882</td>\n      <td>0.647059</td>\n      <td>0.588235</td>\n      <td>0.617647</td>\n      <td>0.065767</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>0.537278</td>\n      <td>0.005300</td>\n      <td>0.043568</td>\n      <td>0.003237</td>\n      <td>False</td>\n      <td>entropy</td>\n      <td>200</td>\n      <td>{'bootstrap': False, 'criterion': 'entropy', '...</td>\n      <td>0.529412</td>\n      <td>0.647059</td>\n      <td>0.588235</td>\n      <td>0.647059</td>\n      <td>0.602941</td>\n      <td>0.048774</td>\n      <td>12</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>1.074315</td>\n      <td>0.017568</td>\n      <td>0.081711</td>\n      <td>0.016315</td>\n      <td>False</td>\n      <td>entropy</td>\n      <td>400</td>\n      <td>{'bootstrap': False, 'criterion': 'entropy', '...</td>\n      <td>0.470588</td>\n      <td>0.705882</td>\n      <td>0.647059</td>\n      <td>0.588235</td>\n      <td>0.602941</td>\n      <td>0.087001</td>\n      <td>11</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "source": [
    "# Tuning the hyperparameters\n",
    "grid_param = {'n_estimators': [10, 50, 100, 200, 400],'criterion': ['gini', 'entropy'],'bootstrap': [True, False]}\n",
    "grid_search=GridSearchCV(RandomForestClassifier(),param_grid=grid_param,cv=skf,n_jobs=-1,verbose=2) \n",
    "grid_search.fit(X_train_pca, y_train)\n",
    "\n",
    "pd.DataFrame(grid_search.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "50\ngini\nFalse\n0.6470588235294118\n"
    }
   ],
   "source": [
    "best_hyperparameters = grid_search.best_params_\n",
    "\n",
    "n_estimators=best_hyperparameters.get('n_estimators')\n",
    "criterion=best_hyperparameters.get('criterion')\n",
    "bootstrap=best_hyperparameters.get('bootstrap')\n",
    "print(n_estimators)\n",
    "print(criterion)\n",
    "print(bootstrap)\n",
    "best_result = grid_search.best_score_  \n",
    "print(best_result) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "RandomForestClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,\n                       criterion='gini', max_depth=None, max_features='auto',\n                       max_leaf_nodes=None, max_samples=None,\n                       min_impurity_decrease=0.0, min_impurity_split=None,\n                       min_samples_leaf=1, min_samples_split=2,\n                       min_weight_fraction_leaf=0.0, n_estimators=50,\n                       n_jobs=None, oob_score=False, random_state=None,\n                       verbose=0, warm_start=False)"
     },
     "metadata": {},
     "execution_count": 35
    }
   ],
   "source": [
    "classifier = RandomForestClassifier(n_estimators=n_estimators, criterion=criterion, bootstrap=bootstrap)\n",
    "classifier.fit(X_train_pca, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0.6818181818181818\n"
    }
   ],
   "source": [
    "classifier_predictions_test=classifier.predict(X_validation_pca)\n",
    "\n",
    "accuracy=metrics.accuracy_score(y_validation, classifier_predictions_test)\n",
    "print(accuracy)\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "The number of samples: 113\nThe number of features: 159\nFitting 4 folds for each of 20 candidates, totalling 80 fits\n[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:    6.1s\n[Parallel(n_jobs=-1)]: Done  80 out of  80 | elapsed:   12.0s finished\n200\nentropy\nTrue\n0.6709558823529411\n0.6956521739130435\n################################################################################\nFitting 4 folds for each of 20 candidates, totalling 80 fits\n[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n[Parallel(n_jobs=-1)]: Done  51 tasks      | elapsed:    6.5s\n[Parallel(n_jobs=-1)]: Done  80 out of  80 | elapsed:   10.2s finished\n100\ngini\nFalse\n0.7904411764705883\n0.7391304347826086\n################################################################################\nFitting 4 folds for each of 20 candidates, totalling 80 fits\n[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n[Parallel(n_jobs=-1)]: Done  51 tasks      | elapsed:    7.8s\n[Parallel(n_jobs=-1)]: Done  80 out of  80 | elapsed:   11.6s finished\n200\nentropy\nFalse\n0.7794117647058822\n0.6363636363636364\n################################################################################\nFitting 4 folds for each of 20 candidates, totalling 80 fits\n[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n[Parallel(n_jobs=-1)]: Done  51 tasks      | elapsed:    7.5s\n50\ngini\nTrue\n0.6617647058823529\n0.7727272727272727\n################################################################################\n[Parallel(n_jobs=-1)]: Done  80 out of  80 | elapsed:   11.9s finished\n"
    }
   ],
   "source": [
    "# Alles wat hierboven staat in de loop gezet\n",
    "\n",
    "# Data\n",
    "from hn.load_data import load_data\n",
    "data = load_data()\n",
    "print(f'The number of samples: {len(data.index)}')\n",
    "print(f'The number of features: {len(data.columns)-1}')\n",
    "y_labels = data['label']\n",
    "del data['label']\n",
    "\n",
    "y = sklearn.preprocessing.label_binarize(y_labels, ['T12', 'T34']) # 0 now stands for T12 and 1 for T34\n",
    "y = [i[0] for i in y]\n",
    "y = np.array(y)\n",
    "\n",
    "cv_4fold = model_selection.StratifiedKFold(n_splits=4, shuffle=True)\n",
    "split_X_train, split_X_test, split_y_train, split_y_test = train_test_split(data, y,\n",
    "                                                    stratify=y, \n",
    "                                                    test_size=0.2)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Loop over the folds\n",
    "for training_index, validation_index in cv_4fold.split(split_X_train, split_y_train):\n",
    "    X_validation = split_X_train.iloc[validation_index]\n",
    "    y_validation = split_y_train[validation_index]\n",
    "    X_train = split_X_train.iloc[training_index]\n",
    "    y_train = split_y_train[training_index]\n",
    "\n",
    "    scaler = preprocessing.StandardScaler()\n",
    "    # scaler = preprocessing.MinMaxScaler()\n",
    "    # scaler = preprocessing.RobustScaler()\n",
    "    scaler.fit(X_train)\n",
    "    X_test_scaled = scaler.transform(X_validation)\n",
    "    X_train_scaled = scaler.transform(X_train)\n",
    "\n",
    "    n_selected_features = 40\n",
    "    n_samples = len(X_train.index)\n",
    "    n_components = min(n_samples, n_selected_features)\n",
    "    pca = decomposition.PCA(n_components)\n",
    "    pca.fit(X_train_scaled)\n",
    "    X_train_pca = pca.transform(X_train_scaled)\n",
    "    X_validation_pca = pca.transform(X_test_scaled)\n",
    "\n",
    "\n",
    "    # Stratified K-fold Cross validation\n",
    "    k=4\n",
    "    skf = StratifiedKFold(k, random_state=0) \n",
    "    # cv kan ook op None --> geeft default --> 5-fold       cross validation\n",
    "\n",
    "    # Tuning the hyperparameters\n",
    "    grid_param = {'n_estimators': [10, 50, 100, 200, 400],'criterion': ['gini', 'entropy'],'bootstrap': [True, False]}\n",
    "    grid_search=GridSearchCV(RandomForestClassifier(),param_grid=grid_param,cv=skf,n_jobs=-1,verbose=2) \n",
    "    grid_search.fit(X_train_pca, y_train)\n",
    "\n",
    "    best_hyperparameters = grid_search.best_params_\n",
    "\n",
    "    # Best hyperparameters\n",
    "    n_estimators=best_hyperparameters.get('n_estimators')\n",
    "    criterion=best_hyperparameters.get('criterion')\n",
    "    bootstrap=best_hyperparameters.get('bootstrap')\n",
    "    print(n_estimators)\n",
    "    print(criterion)\n",
    "    print(bootstrap)\n",
    "    best_result = grid_search.best_score_  \n",
    "    print(best_result)\n",
    "\n",
    "    # Apply classifier with tuned hyperparameters\n",
    "    classifier = RandomForestClassifier(n_estimators=n_estimators, criterion=criterion, bootstrap=bootstrap)\n",
    "    classifier.fit(X_train_pca, y_train)\n",
    "\n",
    "    # Calculate accuracy\n",
    "    classifier_predictions_test=classifier.predict(X_validation_pca)\n",
    "\n",
    "    accuracy=metrics.accuracy_score(y_validation, classifier_predictions_test)\n",
    "    print(accuracy)\n",
    "    print('#'*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}